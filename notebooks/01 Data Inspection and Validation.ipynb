{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection and Validation\n",
    "**Successfully loading data and prepairing it for visualization**\n",
    "\n",
    "NOTE: Goal is to interject how best to format data (dataframe, proper size etc) to take the most advantage of RAPIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Requirements\n",
    "Super short version of intro notebook and restate requirments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "In this section we will show how RAPIDs tools like [CuDF](https://docs.rapids.ai/api/cudf/stable/) can be used with existing Python datavis tools like  [`hvplot`](https://hvplot.holoviz.org/) to load and get a quick look at your data sets. Let's first make sure the necessary imports are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import hvplot.cudf\n",
    "import cupy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "We need to download and extract the sample data we will use for this tutorial. This notebook uses the Kaggle [Chicago Divvy Bicycle Sharing Data](https://www.kaggle.com/yingwurenjian/chicago-divvy-bicycle-sharing-data) dataset. Once the `data.csv` file is downloaded and unzipped, point the paths below at the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "FILENAME = Path(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the CSV file into a CuDF Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_csv(DATA_DIR / FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Shape\n",
    "CuDF supports all the standard Pandas operations for a quick look at the data, e.g. to see the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to inspect the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to see the full list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or see how many trips were made by subscribers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"usertype\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Utility\n",
    "What are useful cols, what do they mean in the real world, is it useful for my problem, do I need to suppliment the data?\n",
    "\n",
    "Having looked at the `df.head()` above, the first thing we might want is to re-load the data, parsing the start end end time columns as datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_csv(DATA_DIR / FILENAME, parse_dates=('starttime', 'stoptime'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we will want to do is to look at trips by day of week. Now that we have real datetime columns, we can use `dt.weekday` to add a `weekday` column to our `cudf` Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weekday\"] = df['starttime'].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection\n",
    "Various visualization techniques to validate if this data makes sense ( e.g. map for proper geospatial encoding, line for time series...)\n",
    "\n",
    "In order to get a very quick look at things, we will use [`hvplot`](https://hvplot.holoviz.org/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic question we might want to ask is how many trip starts are there per day of the week? We can group the `cudf` Dataframe and call `hvplot.bar` directly the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "day_counts = df.groupby(\"weekday\").size().rename(\"count\").reset_index()\n",
    "day_counts.hvplot.bar(\"weekday\", \"count\").opts(title=\"Trip starts, per Week Day\", yformatter=\"%0.0f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another quick look we can generate is to see the overall distribution of trip durations, this time using `hvplot.hist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.hvplot.hist(y=\"tripduration\", bins=50).opts(\n",
    "    title=\"Trips Duration Histrogram\", yformatter=\"%0.0f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hvplot` makes it simple to interrogate different dimensions. For example we can add `groupby=\"month\"` to our call to `hvplot.hist`, and automatically get a slider to see a histogram specific to each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hvplot.hist(y=\"tripduration\", bins=50, groupby=\"month\").opts(\n",
    "    title=\"Trips Duration Histrogram by Month\", yformatter=\"%0.0f\", width=600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hvplot` can also generate KDE distributions, and since we are operating on `cudf` Dataframes, it can do so quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.hvplot.kde(y=\"temperature\").opts(title=\"Distribution of trip temperatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hvplot.heatmap` method can group in two dimensions and colormap according to aggregations on those groups. Here we see *average* trip duration by year and month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.hvplot.heatmap(x='month', y='year', C='tripduration', \n",
    "                  reduce_function=cudf.DataFrame.mean , colorbar=True, cmap=\"Viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also want to bin the data geographically. The `hvplot.hexbin` can show the counts for trip starts overlaid on a tile map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hvplot.hexbin(x='longitude_start', y='latitude_start', geo=True, tiles=\"OSM\").opts(width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "A little cleanup will make some things simpler in future notebooks. \n",
    "\n",
    "One thing that is missing is a list of just station id's and their coordinates. Let's generate that, and save it for later. First, let's group by all the unique \"from\" and \"to\" station id values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_ids = df.groupby(\"from_station_id\")\n",
    "to_ids = df.groupby(\"to_station_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible (but unlikely) that a particular station is only a sink or source for trips. For good measure, let's make sure the group keys are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(from_ids.groups) == set(to_ids.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each group has items for a single station, which all have the same lat/lon. So let's make a new DataFrame by taking a representative from each group, then rename some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = from_ids.nth(1).to_pandas()\n",
    "stations.index.name = \"station_id\"\n",
    "stations.rename(columns={\"latitude_start\": \"lat\", \"longitude_start\": \"lon\"}, inplace=True)\n",
    "stations = stations.reset_index().filter([\"station_id\", \"lat\", \"lon\"])\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally write the results to \"stations.csv\" in our data directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.to_csv(DATA_DIR / \n",
    "                \"stations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
